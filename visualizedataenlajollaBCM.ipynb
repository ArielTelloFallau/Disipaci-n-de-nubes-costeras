{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f75d7cc-6869-40b5-a3c3-3e51f04915fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import datetime \n",
    "import numpy as np\n",
    "import mpmath as mp\n",
    "import pandas as pd\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import copy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib qt\n",
    "\n",
    "from matplotlib.dates import DayLocator, HourLocator, DateFormatter, drange\n",
    "import os \n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "def get_directory(folder):\n",
    "    files= [a for a in listdir(folder) if isfile(join(folder,a))]\n",
    "    \n",
    "    return files\n",
    "import os \n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0389688-937b-41f1-97fc-dc7fd56c2d5d",
   "metadata": {},
   "source": [
    "## DATA BCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf90cd7-1a2f-4941-ad63-2b8b7a32b3eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:/Users/enclab01/Desktop/THESIS/codigos tesis/eventos en la jollaBCM/Mes01.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/eventos en la jollaBCM/Mes010.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/eventos en la jollaBCM/Mes02.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/eventos en la jollaBCM/Mes03.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/eventos en la jollaBCM/Mes04.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/eventos en la jollaBCM/Mes05.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/eventos en la jollaBCM/Mes06.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/eventos en la jollaBCM/Mes07.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/eventos en la jollaBCM/Mes08.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/eventos en la jollaBCM/Mes09.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/eventos en la jollaBCM/Mes11.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/eventos en la jollaBCM/Mes12.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/eventos en la jollaBCM/Mes13.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/eventos en la jollaBCM/Mes14.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/eventos en la jollaBCM/Mes15.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/eventos en la jollaBCM/Mes16.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/eventos en la jollaBCM/Mes17.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/eventos en la jollaBCM/Mes18.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/eventos en la jollaBCM/Mes19.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/eventos en la jollaBCM/Mes20.txt']\n",
      "      index             Dates_and_Hours  BCM  DQF\n",
      "0         0  2021-01-26 00:01:17.707871  1.0  0.0\n",
      "1         1  2021-01-26 00:06:17.707819  1.0  0.0\n",
      "2         2  2021-01-26 00:11:17.707769  1.0  0.0\n",
      "3         3  2021-01-26 00:16:17.707722  1.0  0.0\n",
      "4         4  2021-01-26 00:21:17.707678  1.0  0.0\n",
      "...     ...                         ...  ...  ...\n",
      "6000    427  2021-04-16 23:36:17.706701  0.0  0.0\n",
      "6001    428  2021-04-16 23:41:17.706530  0.0  0.0\n",
      "6002    429  2021-04-16 23:46:17.706353  0.0  0.0\n",
      "6003    430  2021-04-16 23:51:17.706179  0.0  0.0\n",
      "6004    431  2021-04-16 23:56:17.707807  0.0  0.0\n",
      "\n",
      "[6005 rows x 4 columns]\n",
      "      index             Dates_and_Hours  BCM  DQF\n",
      "0         0  2021-01-26 00:01:17.707871  1.0  0.0\n",
      "1         1  2021-01-26 00:06:17.707819  1.0  0.0\n",
      "2         2  2021-01-26 00:11:17.707769  1.0  0.0\n",
      "3         3  2021-01-26 00:16:17.707722  1.0  0.0\n",
      "4         4  2021-01-26 00:21:17.707678  1.0  0.0\n",
      "...     ...                         ...  ...  ...\n",
      "6000    427  2021-04-16 23:36:17.706701  0.0  0.0\n",
      "6001    428  2021-04-16 23:41:17.706530  0.0  0.0\n",
      "6002    429  2021-04-16 23:46:17.706353  0.0  0.0\n",
      "6003    430  2021-04-16 23:51:17.706179  0.0  0.0\n",
      "6004    431  2021-04-16 23:56:17.707807  0.0  0.0\n",
      "\n",
      "[6005 rows x 4 columns]\n",
      "      level_0  index             Dates_and_Hours  BCM  DQF\n",
      "0           0      0  2021-01-26 00:01:17.707871  1.0  0.0\n",
      "1           1      1  2021-01-26 00:06:17.707819  1.0  0.0\n",
      "2           2      2  2021-01-26 00:11:17.707769  1.0  0.0\n",
      "3           3      3  2021-01-26 00:16:17.707722  1.0  0.0\n",
      "4           4      4  2021-01-26 00:21:17.707678  1.0  0.0\n",
      "...       ...    ...                         ...  ...  ...\n",
      "5999     6000    427  2021-04-16 23:36:17.706701  0.0  0.0\n",
      "6000     6001    428  2021-04-16 23:41:17.706530  0.0  0.0\n",
      "6001     6002    429  2021-04-16 23:46:17.706353  0.0  0.0\n",
      "6002     6003    430  2021-04-16 23:51:17.706179  0.0  0.0\n",
      "6003     6004    431  2021-04-16 23:56:17.707807  0.0  0.0\n",
      "\n",
      "[6004 rows x 5 columns]\n",
      "                 Dates_and_Hours  BCM  DQF\n",
      "3466  2000-01-01 11:43:21.000000  0.0  0.0\n",
      "0     2021-01-26 00:01:17.707871  1.0  0.0\n",
      "1     2021-01-26 00:06:17.707819  1.0  0.0\n",
      "2     2021-01-26 00:11:17.707769  1.0  0.0\n",
      "3     2021-01-26 00:16:17.707722  1.0  0.0\n",
      "...                          ...  ...  ...\n",
      "5999  2021-04-16 23:36:17.706701  0.0  0.0\n",
      "6000  2021-04-16 23:41:17.706530  0.0  0.0\n",
      "6001  2021-04-16 23:46:17.706353  0.0  0.0\n",
      "6002  2021-04-16 23:51:17.706179  0.0  0.0\n",
      "6003  2021-04-16 23:56:17.707807  0.0  0.0\n",
      "\n",
      "[6004 rows x 3 columns]\n",
      "rolling 3466    NaN\n",
      "0       NaN\n",
      "1       NaN\n",
      "2       NaN\n",
      "3       NaN\n",
      "       ... \n",
      "5999    0.0\n",
      "6000    NaN\n",
      "6001    NaN\n",
      "6002    NaN\n",
      "6003    NaN\n",
      "Name: Rolling, Length: 6004, dtype: float64\n",
      "                       index  BCM  DQF  Rolling               t_utc\n",
      "0        2000-01-01 11:43:00  0.0  0.0      NaN 2000-01-01 11:43:00\n",
      "1        2000-01-01 11:44:00  NaN  NaN      NaN 2000-01-01 11:44:00\n",
      "2        2000-01-01 11:45:00  NaN  NaN      NaN 2000-01-01 11:45:00\n",
      "3        2000-01-01 11:46:00  NaN  NaN      NaN 2000-01-01 11:46:00\n",
      "4        2000-01-01 11:47:00  NaN  NaN      NaN 2000-01-01 11:47:00\n",
      "...                      ...  ...  ...      ...                 ...\n",
      "11198169 2021-04-16 23:52:00  NaN  NaN      NaN 2021-04-16 23:52:00\n",
      "11198170 2021-04-16 23:53:00  NaN  NaN      NaN 2021-04-16 23:53:00\n",
      "11198171 2021-04-16 23:54:00  NaN  NaN      NaN 2021-04-16 23:54:00\n",
      "11198172 2021-04-16 23:55:00  NaN  NaN      NaN 2021-04-16 23:55:00\n",
      "11198173 2021-04-16 23:56:00  0.0  0.0      NaN 2021-04-16 23:56:00\n",
      "\n",
      "[11198174 rows x 5 columns]\n",
      "                       index  BCM  DQF  Rolling               t_utc\n",
      "0        2000-01-01 11:43:00  0.0  0.0      NaN 2000-01-01 11:43:00\n",
      "1        2000-01-01 11:44:00  NaN  NaN      NaN 2000-01-01 11:44:00\n",
      "2        2000-01-01 11:45:00  NaN  NaN      NaN 2000-01-01 11:45:00\n",
      "3        2000-01-01 11:46:00  NaN  NaN      NaN 2000-01-01 11:46:00\n",
      "4        2000-01-01 11:47:00  NaN  NaN      NaN 2000-01-01 11:47:00\n",
      "...                      ...  ...  ...      ...                 ...\n",
      "11198169 2021-04-16 23:52:00  NaN  NaN      NaN 2021-04-16 23:52:00\n",
      "11198170 2021-04-16 23:53:00  NaN  NaN      NaN 2021-04-16 23:53:00\n",
      "11198171 2021-04-16 23:54:00  NaN  NaN      NaN 2021-04-16 23:54:00\n",
      "11198172 2021-04-16 23:55:00  NaN  NaN      NaN 2021-04-16 23:55:00\n",
      "11198173 2021-04-16 23:56:00  0.0  0.0      NaN 2021-04-16 23:56:00\n",
      "\n",
      "[11198174 rows x 5 columns]\n",
      "0           0.000000e+00\n",
      "1           9.024018e-08\n",
      "2           1.804804e-07\n",
      "3           2.707205e-07\n",
      "4           3.609607e-07\n",
      "                ...     \n",
      "11198169    0.000000e+00\n",
      "11198170    0.000000e+00\n",
      "11198171    0.000000e+00\n",
      "11198172    0.000000e+00\n",
      "11198173    0.000000e+00\n",
      "Name: BCM, Length: 11198174, dtype: float64\n",
      "0           NaN\n",
      "1           NaN\n",
      "2           NaN\n",
      "3           NaN\n",
      "4           NaN\n",
      "           ... \n",
      "11198169    0.0\n",
      "11198170    0.0\n",
      "11198171    0.0\n",
      "11198172    0.0\n",
      "11198173    0.0\n",
      "Name: Rolling, Length: 11198174, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "data_folder=\"C:/Users/enclab01/Desktop/THESIS/codigos tesis/eventos en la jollaBCM\"\n",
    "#data_folder=\"C:/Users/enclab01/Desktop/THESIS/codigos tesis/dataseptiembre2\"\n",
    "list_of_files=get_directory(data_folder)\n",
    "\n",
    "#List with the paths\n",
    "newlist=[]\n",
    "for item in list_of_files:\n",
    "    newlist.append(data_folder+'/'+str(item))\n",
    "print(newlist)\n",
    "\n",
    "import GOES\n",
    "\n",
    "MM_final_table=[]\n",
    "for item in newlist:\n",
    "    #Importing data\n",
    "    titles=['Dates_and_Hours', 'BCM','DQF']\n",
    "    data= pd.read_table(str(item), header=None, names=titles, sep='\\t')\n",
    "    data2=data.iloc[np.arange(1,len(data)),:] #delete the first row\n",
    "    data2=data2.reset_index(drop=True)\n",
    "    MM_final_table.append(data2)\n",
    "\n",
    "    \n",
    "'merge the dataframes'\n",
    "df1=MM_final_table[0]\n",
    "for i in np.arange(1,len(MM_final_table)):\n",
    "    df1=pd.concat([df1, MM_final_table[i]])\n",
    "df1= df1.reset_index() \n",
    "\n",
    "\n",
    "print(df1)\n",
    "df1['BCM']=df1['BCM'].astype(float)\n",
    "df1['DQF']=df1['DQF'].astype(float)\n",
    "'Reemplazar los valores que sean mayores a 50 por nans'\n",
    "df1['BCM'] = df1['BCM'].apply(lambda x: np.nan if x > 50 else x)    \n",
    " \n",
    "print(df1)    \n",
    "\n",
    "'Drop the nans'\n",
    "check_for_nan_1 = df1['BCM'].isnull()\n",
    "data_copy = df1.copy()\n",
    "for i in np.arange(0,len(df1)):\n",
    "    if check_for_nan_1[i]==True:\n",
    "        data_copy.drop(i, axis=0, inplace=True)\n",
    "df1=data_copy\n",
    "df1= df1.reset_index() \n",
    "\n",
    "print(df1)\n",
    "df1=df1[['Dates_and_Hours','BCM' ,'DQF']]\n",
    "# Ordenar en orden ascendente por la columna 'fecha'\n",
    "df1 = df1.sort_values(by='Dates_and_Hours', ascending=True)  \n",
    "\n",
    "\n",
    "print(df1)\n",
    "\n",
    "'Rolling average'\n",
    "df1['Rolling']=df1['BCM'].rolling(10,center=True).mean()    \n",
    "print('rolling',df1['Rolling'])\n",
    "\n",
    "'1 minute resample'\n",
    "#Resample\n",
    "df1['index'] = pd.to_datetime(df1['Dates_and_Hours'])\n",
    "df1.set_index('index', inplace=True)\n",
    "df1=df1.resample('1T').mean()\n",
    "df1['t_utc'] = pd.to_datetime(df1.index.values)\n",
    "df1= df1.reset_index()\n",
    "\n",
    "print(df1)\n",
    "# Ordenar en orden ascendente por la columna 'fecha'\n",
    "df1 = df1.sort_values(by='t_utc', ascending=True)\n",
    "  \n",
    "\n",
    "   \n",
    "print(df1)\n",
    " \n",
    "# -----------------------------------------------------------------    \n",
    "'Veamos que pasa con un interpolate'    \n",
    "    \n",
    "time2=pd.to_datetime(df1['t_utc'])\n",
    "# Interpolar los valores NaN en el DataFrame df\n",
    "df2 = df1['BCM'].interpolate(method='linear')\n",
    "print(df2)    \n",
    "BCM_values2=df2\n",
    "BCM_values2=BCM_values2.astype(float)  \n",
    "\n",
    "df3 = df1['Rolling'].interpolate(method='linear')\n",
    "print(df3)    \n",
    "BCM_values3=df3\n",
    "BCM_values3=BCM_values3.astype(float)  \n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------    \n",
    "    \n",
    "'Drop the nans'\n",
    "check_for_nan_1 = df1['BCM'].isnull()\n",
    "data_copy = df1.copy()\n",
    "for i in np.arange(0,len(df1)):\n",
    "    if check_for_nan_1[i]==True:\n",
    "        data_copy.drop(i, axis=0, inplace=True)\n",
    "df1=data_copy\n",
    "df1= df1.reset_index() \n",
    "\n",
    "print(df1)    \n",
    "\n",
    "time=pd.to_datetime(df1['t_utc'])\n",
    "BCM_values=df1['BCM']\n",
    "DQF_values=df1['DQF']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683d9a92-6001-4e4e-9e63-8da517279c4f",
   "metadata": {},
   "source": [
    "### Visualize the events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40037512-226a-4d63-9ac2-0062106a929a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"Insert the date of interest\"\n",
    "\n",
    "\"event 1\"\n",
    "#fecha_inicio = pd.to_datetime('2021-01-27 08:35:00')\n",
    "#fecha_fin = pd.to_datetime(' 2021-01-27 11:20:00')\n",
    "fecha_inicio1 = pd.to_datetime('2021-01-27 00:35:00')\n",
    "fecha_fin1 = pd.to_datetime(' 2021-01-27 03:20:00')\n",
    "\n",
    "#\n",
    "\n",
    "\"event 2\" \"faltan datos para atras\"\n",
    "#fecha_inicio = pd.to_datetime('2021-02-04 07:40:00')\n",
    "#fecha_fin = pd.to_datetime(' 2021-02-04 12:20:00')\n",
    "fecha_inicio2 = pd.to_datetime('2021-02-03 23:40:00')\n",
    "fecha_fin2 = pd.to_datetime(' 2021-02-04 04:20:00')\n",
    "\n",
    "#\n",
    "\n",
    "\"event 3\" \"faltan datos para atras\"\n",
    "#fecha_inicio = pd.to_datetime('2021-02-17 07:30:00')\n",
    "#fecha_fin = pd.to_datetime(' 2021-02-17 10:50:00')\n",
    "fecha_inicio3 = pd.to_datetime('2021-02-16 23:30:00')\n",
    "fecha_fin3 = pd.to_datetime(' 2021-02-17 02:50:00')\n",
    "\n",
    "#\n",
    "\n",
    "\"event 4\"\n",
    "#fecha_inicio = pd.to_datetime('2021-03-04 09:30:00 ')\n",
    "#fecha_fin = pd.to_datetime('  2021-03-04 11:10:00')\n",
    "fecha_inicio4 = pd.to_datetime('2021-03-04 01:30:00 ')\n",
    "fecha_fin4 = pd.to_datetime('  2021-03-04 03:10:00')\n",
    "\n",
    "#\n",
    "\n",
    "\"event 5\" \"faltan datos para atras\"\n",
    "#fecha_inicio = pd.to_datetime('2021-03-11 06:30:00 ')\n",
    "#fecha_fin = pd.to_datetime('   2021-03-11 11:00:00')\n",
    "fecha_inicio5 = pd.to_datetime('2021-03-10 22:30:00 ')\n",
    "fecha_fin5 = pd.to_datetime('   2021-03-11 03:00:00')\n",
    "\n",
    "#\n",
    "\n",
    "\"event 6\" \"faltan datos para atras\"\n",
    "#fecha_inicio = pd.to_datetime('2021-03-16 07:05:00')\n",
    "#fecha_fin = pd.to_datetime('   2021-03-16 10:50:00')\n",
    "fecha_inicio6 = pd.to_datetime('2021-03-15 23:05:00')\n",
    "fecha_fin6 = pd.to_datetime('   2021-03-16 02:50:00')\n",
    "\n",
    "#\n",
    "\n",
    "\"event 7\" \"faltan datos para atras\"\n",
    "#fecha_inicio = pd.to_datetime('2021-03-20 06:25:00 ')\n",
    "#fecha_fin = pd.to_datetime('   2021-03-20 12:20:00')\n",
    "fecha_inicio7 = pd.to_datetime('2021-03-19 22:25:00')\n",
    "fecha_fin7 = pd.to_datetime('2021-03-20 04:20:00')\n",
    "\n",
    "#\n",
    "\n",
    "\"event 8\" \"faltan datos para atras\"\n",
    "#fecha_inicio = pd.to_datetime('2021-03-21 07:50:00')\n",
    "#fecha_fin = pd.to_datetime(' 2021-03-21 11:15:00')\n",
    "fecha_inicio8 = pd.to_datetime('2021-03-20 23:50:00')\n",
    "fecha_fin8 = pd.to_datetime(' 2021-03-21 03:15:00')\n",
    "\n",
    "#\n",
    "\n",
    "\"event 9\" \"faltan datos para atras\"\n",
    "#fecha_inicio = pd.to_datetime('2021-04-03 06:35:00 ')\n",
    "#fecha_fin = pd.to_datetime('2021-04-03 10:05:00')\n",
    "fecha_inicio9 = pd.to_datetime('2021-04-02 22:35:00')\n",
    "fecha_fin9 = pd.to_datetime('2021-04-03 02:05:00')\n",
    "\n",
    "#\n",
    "\n",
    "\"event 10\" \"faltan datos para atras\"\n",
    "#fecha_inicio = pd.to_datetime('2021-04-09 05:45:00 ')\n",
    "#fecha_fin = pd.to_datetime('2021-04-09 08:35:00')\n",
    "fecha_inicio10 = pd.to_datetime('2021-04-08 21:45:00 ')\n",
    "fecha_fin10 = pd.to_datetime('2021-04-09 00:35:00')\n",
    "\n",
    "#\n",
    "\n",
    "\"event 11\" \"faltan datos para atras\"\n",
    "#fecha_inicio = pd.to_datetime('2021-04-10 05:35:00')\n",
    "#fecha_fin = pd.to_datetime('2021-04-10 09:05:00')\n",
    "fecha_inicio11 = pd.to_datetime('2021-04-09 21:35:00')\n",
    "fecha_fin11 = pd.to_datetime('2021-04-10 01:05:00')\n",
    "\n",
    "#\n",
    "\n",
    "\"event 12\" \"faltan datos para atras\"\n",
    "#fecha_inicio = pd.to_datetime('2021-04-16 06:45:00 ')\n",
    "#fecha_fin = pd.to_datetime('2021-04-16 09:35:00')\n",
    "fecha_inicio12 = pd.to_datetime('2021-04-15 22:45:00 ')\n",
    "fecha_fin12 = pd.to_datetime('2021-04-16 01:35:00')\n",
    "\n",
    "#\n",
    "\n",
    "fechas_de_inicio=[fecha_inicio1,fecha_inicio2,fecha_inicio3,fecha_inicio4,fecha_inicio5,fecha_inicio6,fecha_inicio7,fecha_inicio8,fecha_inicio9,fecha_inicio10,fecha_inicio11,fecha_inicio12]\n",
    "fechas_de_fin=[fecha_fin1,fecha_fin2,fecha_fin3,fecha_fin4,fecha_fin5,fecha_fin6,fecha_fin7,fecha_fin8,fecha_fin9,fecha_fin10,fecha_fin11,fecha_fin12]\n",
    "\n",
    "\n",
    "for i in np.arange(0,len(fechas_de_inicio)):\n",
    "    \n",
    "    df1_filtrado = df1[(df1['t_utc'] >= fechas_de_inicio[i]) & (df1['t_utc'] <= fechas_de_fin[i])]\n",
    "    print(df1_filtrado)\n",
    "    \n",
    "\n",
    "    fig, ax = plt.subplots(1)\n",
    "    fig.autofmt_xdate()\n",
    "\n",
    "    plt.plot(df1_filtrado['t_utc'], df1_filtrado['BCM'],'-x',c='black')\n",
    "\n",
    "\n",
    "    #plt.plot(time, derivative,'-.',c='red') \n",
    "    #plt.plot(time, rolling,'X',c='black') \n",
    "\n",
    "    plt.ylabel('BCM Measurements')\n",
    "    plt.xlabel('Time (UTC)')\n",
    "    xfmt = mdates.DateFormatter('%b %d %H:%M')\n",
    "    ax.xaxis.set_major_formatter(xfmt)\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0e2cc8-f586-475c-9c32-47fbbd9feeb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f889f265-12fe-4bd7-b27a-47a44e99f8f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17ca6b6-add0-4b86-8d4a-0545273795c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558c2f07-f278-4e53-8f99-dfa0267a9362",
   "metadata": {},
   "source": [
    "## ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9de5b9-e6ce-4d3c-8bab-baaf178a0c1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks\n",
    "from scipy.signal import find_peaks, savgol_filter\n",
    "\n",
    "\n",
    "'PEAKS DATOS ORIGINALES'\n",
    "\n",
    "indicess = find_peaks(BCM_values, height=0.00002, prominence=(None, 4000), width=(0.000002, 4000),  rel_height=1)\n",
    "index=indicess[0]\n",
    "\n",
    "pir=[]\n",
    "widths=[]\n",
    "for m in np.arange(0,len(indicess[1]['peak_heights'])):\n",
    "    pir.append([indicess[0][m],indicess[1]['prominences'][m],indicess[1]['peak_heights'][m],abs(indicess[1]['right_ips'][m]-indicess[1]['left_ips'][m])])\n",
    "    widths.append(indicess[1]['widths'][m])    \n",
    "    \n",
    "'ROLLING AVERAGE'\n",
    "\n",
    "#Transform a list into a data column\n",
    "df = pd.DataFrame({'col':BCM_values})\n",
    "dqfvalues=df['col']\n",
    "rolling=dqfvalues.rolling(10,center=True).mean()\n",
    "\n",
    "#'peaks rolling'\n",
    "#indicesrolling,properties = find_peaks(rolling,prominence=1,width=5,  rel_height=1)\n",
    "    \n",
    "    \n",
    "'peaks rolling tras el resample'\n",
    "indicesrolling, properties = find_peaks(BCM_values3, prominence=1,width=5,  rel_height=1)\n",
    "print(len(indicesrolling)) \n",
    "print(len(properties)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae87cd6d-89f6-4ab2-9d98-4f522284ba01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "left=[]\n",
    "right=[]\n",
    "time_left=[]\n",
    "time_right=[]\n",
    "minutes=[]\n",
    "for i in np.arange(0,len(indicesrolling)):\n",
    "    left.append(math.floor(properties[\"left_ips\"][i]))\n",
    "    right.append(math.ceil(properties[\"right_ips\"][i]))\n",
    "    time_left.append(time2[math.floor(properties[\"left_ips\"][i])])\n",
    "    time_right.append(time2[math.ceil(properties[\"right_ips\"][i])])\n",
    "    \n",
    "    diferencia= time2[math.ceil(properties[\"right_ips\"][i])] - time2[math.floor(properties[\"left_ips\"][i])] \n",
    "    minutos_diferencia = diferencia.total_seconds()/60\n",
    "    minutes.append(minutos_diferencia)\n",
    "    \n",
    "    \n",
    "#Create a dataframe with all the variables needed for the analysis \n",
    "dataframe = pd.DataFrame({'Time_left':time_left,'Time_right':time_right,'Left':left,'Right':right, 'Minutes': minutes, 'Prominences': properties[\"prominences\"]})  \n",
    "print(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0611da93-2dc5-4aa5-a643-8c70007d4825",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d1f446-6e1a-4ee2-8b88-62ca977e7635",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(dataframe[\"Minutes\"],bins=200,range=(0,3150))\n",
    "plt.xlabel('Length of Cloud Dissipation (minutes)')\n",
    "plt.ylabel('Count (nº Events)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fb1e57-ce49-4f1a-b26d-e0dbb19a8e41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(dataframe[\"Prominences\"],bins=200,range=(0,30))\n",
    "plt.xlabel('Delta BCM')\n",
    "plt.ylabel('Count (nº Events)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98d1fd3-58df-43d4-915c-f72a3f962e52",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2D HISTOGRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee639f9-39ca-48ed-9a53-9889fe427e9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x=dataframe[\"Minutes\"]\n",
    "xx=x.astype(float)\n",
    "y=dataframe[\"Prominences\"]\n",
    "yy=y.astype(float)\n",
    "\n",
    "xedges=50\n",
    "yedges=50\n",
    "xmin=0\n",
    "xmax=600\n",
    "ymin=0\n",
    "ymax=10  \n",
    "\n",
    "HHH, xedges, yedges= np.histogram2d(xx,yy, bins=(xedges,yedges), range=[[xmin,xmax],[ymin,ymax]])\n",
    "\n",
    "extent = [xmin,xmax, ymin, ymax]\n",
    "\n",
    "fig, ax= plt.subplots()\n",
    "\n",
    "im=ax.imshow(HHH.T ,origin='lower', extent=extent, aspect='auto')\n",
    "plt.colorbar(im, label='# Dissipation events per bin')\n",
    "#plt.clim(0,0.001) #This limit shows how to low values looks like\n",
    "\n",
    "#ax.set_facecolor((0.8,0.8,0.8))\n",
    "ax.set_facecolor('grey')\n",
    "plt.xlabel('Length of Cloud Dissipation (minutes)',fontsize=12)\n",
    "plt.ylabel('BCM variations', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5e4f7e-1fdf-44bb-8f8c-b004c805d618",
   "metadata": {},
   "source": [
    "##  OTROS GRAFICOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ae1020-4c1f-4bde-980e-daa12071b8a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e44e9e2-9eb4-461f-bfc6-90b957f80f0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Definir dos objetos de fecha y hora\n",
    "fecha1 = datetime(2023, 9, 11, 10, 30)  # Año, mes, día, hora, minutos\n",
    "fecha2 = datetime(2023, 9, 11, 12, 45)\n",
    "\n",
    "# Calcular la diferencia entre las dos fechas y obtener el resultado en minutos\n",
    "diferencia = fecha2 - fecha1\n",
    "minutos_diferencia = diferencia.total_seconds() / 60\n",
    "\n",
    "print(minutos_diferencia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d6335a-9883-4a44-afed-4e3478692e7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33ee88c-5ae4-4449-b476-340d89eb26ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'----------------------------------------------------------------------------'\n",
    "fig, ax = plt.subplots(1)\n",
    "fig.autofmt_xdate()\n",
    "\n",
    "plt.plot(time2, BCM_values2,'-x',c='red')\n",
    "plt.plot(time2, BCM_values3,'-x',c='purple') \n",
    "\n",
    "plt.plot(time, BCM_values,'-x',c='black') \n",
    " \n",
    "    \n",
    "#plt.plot(time, derivative,'-.',c='red') \n",
    "#plt.plot(time, rolling,'X',c='black') \n",
    " \n",
    "plt.ylabel('BCM Measurements')\n",
    "plt.xlabel('Time (UTC)')\n",
    "xfmt = mdates.DateFormatter('%b %d %H:%M')\n",
    "ax.xaxis.set_major_formatter(xfmt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b44189c-6d4b-45b4-b60e-84802a1259e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BCM_values3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3012a89-af62-4936-aca8-c683bd004222",
   "metadata": {},
   "source": [
    "## NUEVO PLOT PARA VISUALIZAR LOS ANCHOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185c1c4a-2fc2-45b0-8481-604fc43dbdaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'----------------------------------------------------------------------------'\n",
    "sas=np.arange(0,len(time2))\n",
    "fig, ax = plt.subplots(1)\n",
    "\n",
    "'Ploteamos el rolling average'\n",
    "plt.plot( sas , BCM_values3,'-x',c='black') \n",
    " \n",
    "    \n",
    "plt.ylabel('BCM Measurements')\n",
    "plt.xlabel('Time (UTC)')\n",
    "\n",
    "plt.vlines(x=sas[indicesrolling], ymin=BCM_values3[indicesrolling] - properties[\"prominences\"],\n",
    "           ymax = BCM_values3[indicesrolling], color = \"C1\")\n",
    "plt.hlines(y=properties[\"width_heights\"], xmin=properties[\"left_ips\"],\n",
    "           xmax=properties[\"right_ips\"], color = \"C1\")\n",
    "\n",
    "plt.plot(properties[\"left_ips\"], properties[\"width_heights\"],'X',c='red')\n",
    "plt.plot(properties[\"right_ips\"], properties[\"width_heights\"],'X',c='blue')\n",
    "\n",
    "\n",
    "# Plotea líneas verticales en cada punto\n",
    "for i in range(len(left)):\n",
    "    ax.vlines(left[i], ymin=BCM_values3[left[i]], ymax=BCM_values3[left[i]]+10, color='purple', linestyle='-', alpha=0.5)\n",
    "# Plotea líneas verticales en cada punto\n",
    "for i in range(len(right)):\n",
    "    ax.vlines(right[i], ymin=BCM_values3[right[i]], ymax=BCM_values3[right[i]]+10, color='purple', linestyle='-', alpha=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532f0df2-8299-40bb-94a2-c34951c00cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(properties[\"prominences\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47811e4c-16d8-4a3b-a847-875183ccf33e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ddbd42-c7cb-4cfd-9a45-c572e1142a31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff36fb75-dba7-41b5-83b4-f8c1751f9453",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#FIRST PLOT\n",
    "plt.figure()\n",
    "ax2=plt.subplot(212)\n",
    "figsize=(20,4)\n",
    "   \n",
    "plt.plot(time, BCM_values,'-x',c='black')     \n",
    "plt.plot(time, rolling,'-x',c='purple') \n",
    "#plt.text(0.01, 0.75, \"D)\", fontweight=\"bold\", fontsize=13 ,transform=ax7.transAxes)\n",
    "plt.ylabel('BCM (adimensional)',fontsize=13)\n",
    "\n",
    "\n",
    "\n",
    "#SECOND PLOT\n",
    "\n",
    "ax1=plt.subplot(211,sharex=ax2)\n",
    "figsize=(20,4)\n",
    "plt.plot(time2,HT_values ,'-x',color='black')\n",
    "plt.plot(time2,10000*np.ones(len(time2)))\n",
    "plt.ylabel('Altitude (m)',fontsize=13)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
