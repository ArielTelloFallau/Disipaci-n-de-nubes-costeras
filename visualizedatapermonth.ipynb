{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f75d7cc-6869-40b5-a3c3-3e51f04915fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import datetime \n",
    "import numpy as np\n",
    "import mpmath as mp\n",
    "import pandas as pd\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import copy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib qt\n",
    "\n",
    "from matplotlib.dates import DayLocator, HourLocator, DateFormatter, drange\n",
    "import os \n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "def get_directory(folder):\n",
    "    files= [a for a in listdir(folder) if isfile(join(folder,a))]\n",
    "    \n",
    "    return files\n",
    "import os \n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0389688-937b-41f1-97fc-dc7fd56c2d5d",
   "metadata": {},
   "source": [
    "## DATA COD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acf90cd7-1a2f-4941-ad63-2b8b7a32b3eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:/Users/enclab01/Desktop/THESIS/codigos tesis/Datos Point Sur/2019/Mes01.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/Datos Point Sur/2019/Mes010.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/Datos Point Sur/2019/Mes02.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/Datos Point Sur/2019/Mes03.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/Datos Point Sur/2019/Mes04.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/Datos Point Sur/2019/Mes05.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/Datos Point Sur/2019/Mes06.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/Datos Point Sur/2019/Mes07.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/Datos Point Sur/2019/Mes08.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/Datos Point Sur/2019/Mes09.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/Datos Point Sur/2019/Mes11.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/Datos Point Sur/2019/Mes12.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/Datos Point Sur/2019/Mes13.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/Datos Point Sur/2019/Mes14.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/Datos Point Sur/2019/Mes15.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/Datos Point Sur/2019/Mes16.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/Datos Point Sur/2019/Mes17.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/Datos Point Sur/2019/Mes18.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/Datos Point Sur/2019/Mes19.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/Datos Point Sur/2019/Mes20.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/Datos Point Sur/2019/Mes21.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/Datos Point Sur/2019/Mes22.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/Datos Point Sur/2019/Mes23.txt']\n",
      "       index             Dates_and_Hours  COD  DQF\n",
      "0          0  2019-09-01 00:01:19.703999  NaN  6.0\n",
      "1          1  2019-09-01 00:06:19.703817  NaN  6.0\n",
      "2          2  2019-09-01 00:11:19.703627  NaN  6.0\n",
      "3          3  2019-09-01 00:16:19.705240  NaN  6.0\n",
      "4          4  2019-09-01 00:21:19.705045  NaN  6.0\n",
      "...      ...                         ...  ...  ...\n",
      "10766    495  2019-08-29 09:36:19.669421  NaN  7.0\n",
      "10767    496  2019-08-29 09:41:19.669026  NaN  7.0\n",
      "10768    497  2019-08-29 09:46:19.668633  NaN  7.0\n",
      "10769    498  2019-08-29 09:51:19.668244  NaN  7.0\n",
      "10770    499  2019-08-29 09:56:19.667859  NaN  7.0\n",
      "\n",
      "[10771 rows x 4 columns]\n",
      "       index             Dates_and_Hours  COD  DQF\n",
      "0          0  2019-09-01 00:01:19.703999  NaN  6.0\n",
      "1          1  2019-09-01 00:06:19.703817  NaN  6.0\n",
      "2          2  2019-09-01 00:11:19.703627  NaN  6.0\n",
      "3          3  2019-09-01 00:16:19.705240  NaN  6.0\n",
      "4          4  2019-09-01 00:21:19.705045  NaN  6.0\n",
      "...      ...                         ...  ...  ...\n",
      "10766    495  2019-08-29 09:36:19.669421  NaN  7.0\n",
      "10767    496  2019-08-29 09:41:19.669026  NaN  7.0\n",
      "10768    497  2019-08-29 09:46:19.668633  NaN  7.0\n",
      "10769    498  2019-08-29 09:51:19.668244  NaN  7.0\n",
      "10770    499  2019-08-29 09:56:19.667859  NaN  7.0\n",
      "\n",
      "[10771 rows x 4 columns]\n",
      "     level_0  index             Dates_and_Hours        COD  DQF\n",
      "0        145    145  2019-09-01 12:06:19.667155  16.000002  1.0\n",
      "1        148    148  2019-09-01 12:21:19.668078  16.000002  1.0\n",
      "2        500      0  2019-09-16 16:06:19.692071   9.756754  0.0\n",
      "3        501      1  2019-09-16 16:11:19.691803   7.066077  0.0\n",
      "4        503      3  2019-09-16 16:21:19.691258   6.648559  0.0\n",
      "..       ...    ...                         ...        ...  ...\n",
      "656    10527    256  2019-08-28 13:41:19.671141  16.000002  5.0\n",
      "657    10528    257  2019-08-28 13:46:19.670968  16.000002  5.0\n",
      "658    10530    259  2019-08-28 13:56:19.672447  16.000002  5.0\n",
      "659    10531    260  2019-08-28 14:01:19.672285  16.000002  5.0\n",
      "660    10547    276  2019-08-28 15:21:19.675933   1.626126  4.0\n",
      "\n",
      "[661 rows x 5 columns]\n",
      "                Dates_and_Hours        COD  DQF\n",
      "621  2019-08-03 06:01:19.711913  16.000002  1.0\n",
      "622  2019-08-03 10:26:19.663699  16.000002  1.0\n",
      "623  2019-08-03 10:31:19.663382  16.000002  1.0\n",
      "624  2019-08-03 23:51:19.699493   1.760415  0.0\n",
      "625  2019-08-03 23:56:19.699320   2.700443  0.0\n",
      "..                          ...        ...  ...\n",
      "616  2019-09-30 12:46:19.681111   2.475813  1.0\n",
      "617  2019-09-30 12:51:19.680839   3.403632  1.0\n",
      "618  2019-09-30 12:56:19.680557   3.357241  1.0\n",
      "619  2019-09-30 13:06:19.680001   4.436442  1.0\n",
      "620  2019-09-30 13:46:19.681310   3.174119  1.0\n",
      "\n",
      "[661 rows x 3 columns]\n",
      "rolling 621         NaN\n",
      "622         NaN\n",
      "623         NaN\n",
      "624         NaN\n",
      "625         NaN\n",
      "         ...   \n",
      "616    2.805189\n",
      "617         NaN\n",
      "618         NaN\n",
      "619         NaN\n",
      "620         NaN\n",
      "Name: Rolling, Length: 661, dtype: float64\n",
      "                    index        COD  DQF  Rolling               t_utc\n",
      "0     2019-08-03 06:01:00  16.000002  1.0      NaN 2019-08-03 06:01:00\n",
      "1     2019-08-03 06:02:00        NaN  NaN      NaN 2019-08-03 06:02:00\n",
      "2     2019-08-03 06:03:00        NaN  NaN      NaN 2019-08-03 06:03:00\n",
      "3     2019-08-03 06:04:00        NaN  NaN      NaN 2019-08-03 06:04:00\n",
      "4     2019-08-03 06:05:00        NaN  NaN      NaN 2019-08-03 06:05:00\n",
      "...                   ...        ...  ...      ...                 ...\n",
      "83981 2019-09-30 13:42:00        NaN  NaN      NaN 2019-09-30 13:42:00\n",
      "83982 2019-09-30 13:43:00        NaN  NaN      NaN 2019-09-30 13:43:00\n",
      "83983 2019-09-30 13:44:00        NaN  NaN      NaN 2019-09-30 13:44:00\n",
      "83984 2019-09-30 13:45:00        NaN  NaN      NaN 2019-09-30 13:45:00\n",
      "83985 2019-09-30 13:46:00   3.174119  1.0      NaN 2019-09-30 13:46:00\n",
      "\n",
      "[83986 rows x 5 columns]\n",
      "                    index        COD  DQF  Rolling               t_utc\n",
      "0     2019-08-03 06:01:00  16.000002  1.0      NaN 2019-08-03 06:01:00\n",
      "1     2019-08-03 06:02:00        NaN  NaN      NaN 2019-08-03 06:02:00\n",
      "2     2019-08-03 06:03:00        NaN  NaN      NaN 2019-08-03 06:03:00\n",
      "3     2019-08-03 06:04:00        NaN  NaN      NaN 2019-08-03 06:04:00\n",
      "4     2019-08-03 06:05:00        NaN  NaN      NaN 2019-08-03 06:05:00\n",
      "...                   ...        ...  ...      ...                 ...\n",
      "83981 2019-09-30 13:42:00        NaN  NaN      NaN 2019-09-30 13:42:00\n",
      "83982 2019-09-30 13:43:00        NaN  NaN      NaN 2019-09-30 13:43:00\n",
      "83983 2019-09-30 13:44:00        NaN  NaN      NaN 2019-09-30 13:44:00\n",
      "83984 2019-09-30 13:45:00        NaN  NaN      NaN 2019-09-30 13:45:00\n",
      "83985 2019-09-30 13:46:00   3.174119  1.0      NaN 2019-09-30 13:46:00\n",
      "\n",
      "[83986 rows x 5 columns]\n",
      "0        16.000002\n",
      "1        16.000002\n",
      "2        16.000002\n",
      "3        16.000002\n",
      "4        16.000002\n",
      "           ...    \n",
      "83981     3.300351\n",
      "83982     3.268793\n",
      "83983     3.237235\n",
      "83984     3.205677\n",
      "83985     3.174119\n",
      "Name: COD, Length: 83986, dtype: float64\n",
      "0             NaN\n",
      "1             NaN\n",
      "2             NaN\n",
      "3             NaN\n",
      "4             NaN\n",
      "           ...   \n",
      "83981    2.805189\n",
      "83982    2.805189\n",
      "83983    2.805189\n",
      "83984    2.805189\n",
      "83985    2.805189\n",
      "Name: Rolling, Length: 83986, dtype: float64\n",
      "     level_0               index        COD  DQF   Rolling               t_utc\n",
      "0          0 2019-08-03 06:01:00  16.000002  1.0       NaN 2019-08-03 06:01:00\n",
      "1        265 2019-08-03 10:26:00  16.000002  1.0       NaN 2019-08-03 10:26:00\n",
      "2        270 2019-08-03 10:31:00  16.000002  1.0       NaN 2019-08-03 10:31:00\n",
      "3       1070 2019-08-03 23:51:00   1.760415  0.0       NaN 2019-08-03 23:51:00\n",
      "4       1075 2019-08-03 23:56:00   2.700443  0.0       NaN 2019-08-03 23:56:00\n",
      "..       ...                 ...        ...  ...       ...                 ...\n",
      "656    83925 2019-09-30 12:46:00   2.475813  1.0  2.805189 2019-09-30 12:46:00\n",
      "657    83930 2019-09-30 12:51:00   3.403632  1.0       NaN 2019-09-30 12:51:00\n",
      "658    83935 2019-09-30 12:56:00   3.357241  1.0       NaN 2019-09-30 12:56:00\n",
      "659    83945 2019-09-30 13:06:00   4.436442  1.0       NaN 2019-09-30 13:06:00\n",
      "660    83985 2019-09-30 13:46:00   3.174119  1.0       NaN 2019-09-30 13:46:00\n",
      "\n",
      "[661 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "#data_folder=\"C:/Users/enclab01/Desktop/THESIS/codigos tesis/Datos San Nicolas/dataseptiembre\"\n",
    "#data_folder=\"C:/Users/enclab01/Desktop/THESIS/codigos tesis/dataseptiembre2\"\n",
    "#data_folder=\"C:/Users/enclab01/Desktop/THESIS/codigos tesis/Datos Point Sur/Julio 2022\"\n",
    "data_folder=\"C:/Users/enclab01/Desktop/THESIS/codigos tesis/Datos Point Sur/2019\"\n",
    "\n",
    "\n",
    "\n",
    "list_of_files=get_directory(data_folder)\n",
    "\n",
    "#List with the paths\n",
    "newlist=[]\n",
    "for item in list_of_files:\n",
    "    newlist.append(data_folder+'/'+str(item))\n",
    "print(newlist)\n",
    "\n",
    "import GOES\n",
    "\n",
    "MM_final_table=[]\n",
    "for item in newlist:\n",
    "    #Importing data\n",
    "    titles=['Dates_and_Hours', 'COD','DQF']\n",
    "    data= pd.read_table(str(item), header=None, names=titles, sep='\\t')\n",
    "    data2=data.iloc[np.arange(1,len(data)),:] #delete the first row\n",
    "    data2=data2.reset_index(drop=True)\n",
    "    MM_final_table.append(data2)\n",
    "\n",
    "    \n",
    "'merge the dataframes'\n",
    "df1=MM_final_table[0]\n",
    "for i in np.arange(1,len(MM_final_table)):\n",
    "    df1=pd.concat([df1, MM_final_table[i]])\n",
    "df1= df1.reset_index() \n",
    "\n",
    "\n",
    "print(df1)\n",
    "df1['COD']=df1['COD'].astype(float)\n",
    "df1['DQF']=df1['DQF'].astype(float)\n",
    "'Reemplazar los valores que sean mayores a 50 por nans'\n",
    "df1['COD'] = df1['COD'].apply(lambda x: np.nan if x > 50 else x)    \n",
    " \n",
    "print(df1)    \n",
    "\n",
    "'Drop the nans'\n",
    "check_for_nan_1 = df1['COD'].isnull()\n",
    "data_copy = df1.copy()\n",
    "for i in np.arange(0,len(df1)):\n",
    "    if check_for_nan_1[i]==True:\n",
    "        data_copy.drop(i, axis=0, inplace=True)\n",
    "df1=data_copy\n",
    "df1= df1.reset_index() \n",
    "\n",
    "print(df1)\n",
    "df1=df1[['Dates_and_Hours','COD' ,'DQF']]\n",
    "# Ordenar en orden ascendente por la columna 'fecha'\n",
    "df1 = df1.sort_values(by='Dates_and_Hours', ascending=True)  \n",
    "\n",
    "\n",
    "print(df1)\n",
    "\n",
    "'Rolling average'\n",
    "df1['Rolling']=df1['COD'].rolling(10,center=True).mean()    \n",
    "print('rolling',df1['Rolling'])\n",
    "\n",
    "'1 minute resample'\n",
    "#Resample\n",
    "df1['index'] = pd.to_datetime(df1['Dates_and_Hours'])\n",
    "df1.set_index('index', inplace=True)\n",
    "df1=df1.resample('1T').mean()\n",
    "df1['t_utc'] = pd.to_datetime(df1.index.values)\n",
    "df1= df1.reset_index()\n",
    "\n",
    "print(df1)\n",
    "# Ordenar en orden ascendente por la columna 'fecha'\n",
    "df1 = df1.sort_values(by='t_utc', ascending=True)\n",
    "  \n",
    "\n",
    "   \n",
    "print(df1)\n",
    " \n",
    "# -----------------------------------------------------------------    \n",
    "'Veamos que pasa con un interpolate'    \n",
    "    \n",
    "time2=pd.to_datetime(df1['t_utc'])\n",
    "# Interpolar los valores NaN en el DataFrame df\n",
    "df2 = df1['COD'].interpolate(method='linear')\n",
    "print(df2)    \n",
    "COD_values2=df2\n",
    "COD_values2=COD_values2.astype(float)  \n",
    "\n",
    "df3 = df1['Rolling'].interpolate(method='linear')\n",
    "print(df3)    \n",
    "COD_values3=df3\n",
    "COD_values3=COD_values3.astype(float)  \n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------    \n",
    "    \n",
    "'Drop the nans'\n",
    "check_for_nan_1 = df1['COD'].isnull()\n",
    "data_copy = df1.copy()\n",
    "for i in np.arange(0,len(df1)):\n",
    "    if check_for_nan_1[i]==True:\n",
    "        data_copy.drop(i, axis=0, inplace=True)\n",
    "df1=data_copy\n",
    "df1= df1.reset_index() \n",
    "\n",
    "print(df1)    \n",
    "\n",
    "time=pd.to_datetime(df1['t_utc'])\n",
    "COD_values=df1['COD']\n",
    "DQF_values=df1['DQF']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de5937b-832d-47a0-9e46-92629cf20324",
   "metadata": {},
   "source": [
    "## DATA ALTITUDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03a240de-d03f-4d2a-9b55-61af599bb884",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:/Users/enclab01/Desktop/THESIS/codigos tesis/Datos San Nicolas/dataseptiembrealtura/Septiembre2022-01.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/Datos San Nicolas/dataseptiembrealtura/Septiembre2022-02.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/Datos San Nicolas/dataseptiembrealtura/Septiembre2022-03.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/Datos San Nicolas/dataseptiembrealtura/Septiembre2022-04.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/Datos San Nicolas/dataseptiembrealtura/Septiembre2022-05.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/Datos San Nicolas/dataseptiembrealtura/Septiembre2022-06.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/Datos San Nicolas/dataseptiembrealtura/Septiembre2022-07.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/Datos San Nicolas/dataseptiembrealtura/Septiembre2022-08.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/Datos San Nicolas/dataseptiembrealtura/Septiembre2022-09.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/Datos San Nicolas/dataseptiembrealtura/Septiembre2022-10.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/Datos San Nicolas/dataseptiembrealtura/Septiembre2022-11.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/Datos San Nicolas/dataseptiembrealtura/Septiembre2022-12.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/Datos San Nicolas/dataseptiembrealtura/Septiembre2022-13.txt', 'C:/Users/enclab01/Desktop/THESIS/codigos tesis/Datos San Nicolas/dataseptiembrealtura/Septiembre2022-14.txt']\n",
      "                 Dates_and_Hours         HT  DQF\n",
      "0     2022-09-01 00:01:17.736182  12510.910  0.0\n",
      "1     2022-09-01 00:06:17.736186  12494.124  0.0\n",
      "2     2022-09-01 00:11:17.736185  12467.571  0.0\n",
      "3     2022-09-01 00:16:17.736182  12481.000  0.0\n",
      "4     2022-09-01 00:21:17.737981  12244.468  0.0\n",
      "...                          ...        ...  ...\n",
      "4139  2022-09-30 23:36:17.700203  11197.619  0.0\n",
      "4140  2022-09-30 23:41:17.700283  11260.796  0.0\n",
      "4141  2022-09-30 23:46:17.700373  11532.122  0.0\n",
      "4142  2022-09-30 23:51:17.700464  10425.453  0.0\n",
      "4143  2022-09-30 23:56:17.702354   9568.747  0.0\n",
      "\n",
      "[4144 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "data_folder=\"C:/Users/enclab01/Desktop/THESIS/codigos tesis/Datos San Nicolas/dataseptiembrealtura\"\n",
    "list_of_files=get_directory(data_folder)\n",
    "\n",
    "#List with the paths\n",
    "newlist=[]\n",
    "for item in list_of_files:\n",
    "    newlist.append(data_folder+'/'+str(item))\n",
    "print(newlist)\n",
    "\n",
    "import GOES\n",
    "\n",
    "MM_final_table=[]\n",
    "for item in newlist:\n",
    "    #Importing data\n",
    "    titles=['Dates_and_Hours', 'HT', 'DQF']\n",
    "    data= pd.read_table(str(item), header=None, names=titles, sep='\\t',parse_dates=['Dates_and_Hours'])\n",
    "    data2=data.iloc[np.arange(1,len(data)),:] #delete the first row\n",
    "    data2=data2.reset_index(drop=True)\n",
    "    MM_final_table.append(data2)\n",
    "\n",
    "\n",
    "'merge the dataframes'\n",
    "df2=MM_final_table[0]\n",
    "for i in np.arange(1,len(MM_final_table)):\n",
    "    df2=pd.concat([df2, MM_final_table[i]])\n",
    "df2= df2.reset_index() \n",
    "\n",
    "\n",
    "'Drop the nans'\n",
    "check_for_nan_1 = df2['HT'].isnull()\n",
    "data_copy = df2.copy()\n",
    "for i in np.arange(0,len(df2)):\n",
    "    if check_for_nan_1[i]==True:\n",
    "        data_copy.drop(i, axis=0, inplace=True)\n",
    "df2=data_copy\n",
    "df2= df2.reset_index() \n",
    "\n",
    "\n",
    "# Ordenar en orden ascendente por la columna 'fecha'\n",
    "df2 = df2.sort_values(by='Dates_and_Hours', ascending=True)\n",
    "\n",
    "\n",
    "df2['HT']=df2['HT'].astype(float)\n",
    "df2['DQF']=df2['DQF'].astype(float)\n",
    "\n",
    "# 'Reemplazar los valores que sean mayores a 50 por 55 para que sea mas facil el analisis de datos'\n",
    "# Reemplazar los valores mayores que 50 por 55 en la columna 'columna_valor'\n",
    "# df1['COD'] = df1['COD'].apply(lambda x: 55 if x > 50 else x)\n",
    "\n",
    "df2=df2[['Dates_and_Hours','HT','DQF']]\n",
    "print(df2)\n",
    "\n",
    "#time2=pd.to_datetime(df2['Dates_and_Hours'])\n",
    "HT_values=df2['HT']\n",
    "DQF_values2=df2['DQF']\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b21c9632-e087-4199-914a-09241c1491f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "#Resample\n",
    "df2['index'] = pd.to_datetime(df2['Dates_and_Hours'])\n",
    "df2.set_index('index', inplace=True)\n",
    "data2=df2.resample('1T').mean()\n",
    "\n",
    "data2['t_utc'] = pd.to_datetime(data2.index.values)\n",
    "data2= data2.reset_index()\n",
    "\n",
    "altitudekm=[]\n",
    "\n",
    "for item in data2['HT']:\n",
    "    altitudekm.append(item/1000)\n",
    "\n",
    "'----------------------------------------------------------------------------'\n",
    "fig, ax = plt.subplots(1)\n",
    "fig.autofmt_xdate()\n",
    "#plt.plot(time, COD_values,'-x',c='black') \n",
    "#plt.plot(time, derivative,'-.',c='red') \n",
    "plt.plot(data2['t_utc'],altitudekm,'-x')\n",
    " \n",
    "plt.ylabel('Altitude (Km)')\n",
    "plt.xlabel('Time (UTC)')\n",
    "xfmt = mdates.DateFormatter('%b %d %H:%M')\n",
    "ax.xaxis.set_major_formatter(xfmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558c2f07-f278-4e53-8f99-dfa0267a9362",
   "metadata": {},
   "source": [
    "## ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc9de5b9-e6ce-4d3c-8bab-baaf178a0c1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "from scipy.signal import find_peaks\n",
    "from scipy.signal import find_peaks, savgol_filter\n",
    "\n",
    "\n",
    "'PEAKS DATOS ORIGINALES'\n",
    "\n",
    "indicess = find_peaks(COD_values, height=0.00002, prominence=(None, 4000), width=(0.000002, 4000),  rel_height=1)\n",
    "index=indicess[0]\n",
    "\n",
    "pir=[]\n",
    "widths=[]\n",
    "for m in np.arange(0,len(indicess[1]['peak_heights'])):\n",
    "    pir.append([indicess[0][m],indicess[1]['prominences'][m],indicess[1]['peak_heights'][m],abs(indicess[1]['right_ips'][m]-indicess[1]['left_ips'][m])])\n",
    "    widths.append(indicess[1]['widths'][m])    \n",
    "    \n",
    "'ROLLING AVERAGE'\n",
    "\n",
    "#Transform a list into a data column\n",
    "df = pd.DataFrame({'col':COD_values})\n",
    "dqfvalues=df['col']\n",
    "rolling=dqfvalues.rolling(10,center=True).mean()\n",
    "\n",
    "#'peaks rolling'\n",
    "#indicesrolling,properties = find_peaks(rolling,prominence=1,width=5,  rel_height=1)\n",
    "    \n",
    "    \n",
    "'peaks rolling tras el resample'\n",
    "indicesrolling, properties = find_peaks(COD_values3, prominence=1,width=5,  rel_height=1)\n",
    "print(len(indicesrolling)) \n",
    "print(len(properties)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae87cd6d-89f6-4ab2-9d98-4f522284ba01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Time_left          Time_right   Left  Right  Minutes  Prominences\n",
      "0  2019-08-04 00:46:00 2019-09-05 09:58:00   1125  47757  46632.0    10.823014\n",
      "1  2019-09-05 10:51:00 2019-09-07 15:02:00  47810  50941   3131.0     2.929956\n",
      "2  2019-09-07 15:46:00 2019-09-15 01:54:00  50985  61673  10688.0     3.271540\n",
      "3  2019-09-15 02:02:00 2019-09-15 07:01:00  61681  61980    299.0     8.096201\n",
      "4  2019-09-15 02:01:00 2019-09-15 12:11:00  61680  62290    610.0     9.863209\n",
      "5  2019-09-15 10:21:00 2019-09-15 11:17:00  62180  62236     56.0     3.147261\n",
      "6  2019-09-15 13:54:00 2019-09-15 17:51:00  62393  62630    237.0     2.403052\n",
      "7  2019-09-15 18:08:00 2019-09-15 21:11:00  62647  62830    183.0     4.218160\n",
      "8  2019-09-15 12:57:00 2019-09-16 07:26:00  62336  63445   1109.0     8.504442\n",
      "9  2019-09-16 10:15:00 2019-09-16 14:06:00  63614  63845    231.0     2.764902\n",
      "10 2019-09-16 07:28:00 2019-09-23 03:11:00  63447  73270   9823.0    16.812820\n",
      "11 2019-09-16 17:26:00 2019-09-16 19:20:00  64045  64159    114.0     8.839189\n",
      "12 2019-09-16 22:06:00 2019-09-22 21:48:00  64325  72947   8622.0     2.106394\n",
      "13 2019-09-25 16:58:00 2019-09-25 23:16:00  76977  77355    378.0     2.516832\n",
      "14 2019-09-26 23:38:00 2019-09-27 17:51:00  78817  79910   1093.0    13.841844\n",
      "15 2019-09-27 19:35:00 2019-09-27 21:11:00  80014  80110     96.0     8.650451\n",
      "16 2019-09-23 05:31:00 2019-09-30 11:46:00  73410  83865  10455.0    32.252956\n",
      "17 2019-09-27 23:36:00 2019-09-28 00:47:00  80255  80326     71.0     5.390387\n",
      "18 2019-09-28 23:21:00 2019-09-30 11:25:00  81680  83844   2164.0     1.326293\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "left=[]\n",
    "right=[]\n",
    "time_left=[]\n",
    "time_right=[]\n",
    "minutes=[]\n",
    "for i in np.arange(0,len(indicesrolling)):\n",
    "    left.append(math.floor(properties[\"left_ips\"][i]))\n",
    "    right.append(math.ceil(properties[\"right_ips\"][i]))\n",
    "    time_left.append(time2[math.floor(properties[\"left_ips\"][i])])\n",
    "    time_right.append(time2[math.ceil(properties[\"right_ips\"][i])])\n",
    "    \n",
    "    diferencia= time2[math.ceil(properties[\"right_ips\"][i])] - time2[math.floor(properties[\"left_ips\"][i])] \n",
    "    minutos_diferencia = diferencia.total_seconds()/60\n",
    "    minutes.append(minutos_diferencia)\n",
    "    \n",
    "    \n",
    "#Create a dataframe with all the variables needed for the analysis \n",
    "dataframe = pd.DataFrame({'Time_left':time_left,'Time_right':time_right,'Left':left,'Right':right, 'Minutes': minutes, 'Prominences': properties[\"prominences\"]})  \n",
    "print(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e479c16-27ec-413d-a9cd-d3e2b6d65974",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataframe.to_csv('dataframe events'+\".txt\", index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0611da93-2dc5-4aa5-a643-8c70007d4825",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39d1f446-6e1a-4ee2-8b88-62ca977e7635",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Count (nº Events)')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.hist(dataframe[\"Minutes\"],bins=200,range=(0,3150))\n",
    "plt.xlabel('Length of Cloud Dissipation (minutes)')\n",
    "plt.ylabel('Count (nº Events)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2fb1e57-ce49-4f1a-b26d-e0dbb19a8e41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Count (nº Events)')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.hist(dataframe[\"Prominences\"],bins=200,range=(0,30))\n",
    "plt.xlabel('Delta COD')\n",
    "plt.ylabel('Count (nº Events)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98d1fd3-58df-43d4-915c-f72a3f962e52",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2D HISTOGRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dee639f9-39ca-48ed-9a53-9889fe427e9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'COD variations')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=dataframe[\"Minutes\"]\n",
    "xx=x.astype(float)\n",
    "y=dataframe[\"Prominences\"]\n",
    "yy=y.astype(float)\n",
    "\n",
    "xedges=50\n",
    "yedges=50\n",
    "xmin=0\n",
    "xmax=600\n",
    "ymin=0\n",
    "ymax=10  \n",
    "\n",
    "HHH, xedges, yedges= np.histogram2d(xx,yy, bins=(xedges,yedges), range=[[xmin,xmax],[ymin,ymax]])\n",
    "\n",
    "extent = [xmin,xmax, ymin, ymax]\n",
    "\n",
    "fig, ax= plt.subplots()\n",
    "\n",
    "im=ax.imshow(HHH.T ,origin='lower', extent=extent, aspect='auto')\n",
    "plt.colorbar(im, label='# Dissipation events per bin')\n",
    "#plt.clim(0,0.001) #This limit shows how to low values looks like\n",
    "\n",
    "#ax.set_facecolor((0.8,0.8,0.8))\n",
    "ax.set_facecolor('grey')\n",
    "plt.xlabel('Length of Cloud Dissipation (minutes)',fontsize=12)\n",
    "plt.ylabel('COD variations', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5e4f7e-1fdf-44bb-8f8c-b004c805d618",
   "metadata": {},
   "source": [
    "##  OTROS GRAFICOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ae1020-4c1f-4bde-980e-daa12071b8a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e44e9e2-9eb4-461f-bfc6-90b957f80f0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135.0\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Definir dos objetos de fecha y hora\n",
    "fecha1 = datetime(2023, 9, 11, 10, 30)  # Año, mes, día, hora, minutos\n",
    "fecha2 = datetime(2023, 9, 11, 12, 45)\n",
    "\n",
    "# Calcular la diferencia entre las dos fechas y obtener el resultado en minutos\n",
    "diferencia = fecha2 - fecha1\n",
    "minutos_diferencia = diferencia.total_seconds() / 60\n",
    "\n",
    "print(minutos_diferencia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d6335a-9883-4a44-afed-4e3478692e7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e33ee88c-5ae4-4449-b476-340d89eb26ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'----------------------------------------------------------------------------'\n",
    "fig, ax = plt.subplots(1)\n",
    "fig.autofmt_xdate()\n",
    "\n",
    "#plt.plot(time2, COD_values2,'-x',c='red')\n",
    "plt.plot(time2, COD_values3,'-x',c='purple') \n",
    "\n",
    "#plt.plot(time, COD_values,'-x',c='black') \n",
    " \n",
    "    \n",
    "#plt.plot(time, derivative,'-.',c='red') \n",
    "#plt.plot(time, rolling,'X',c='black') \n",
    " \n",
    "plt.ylabel('COD Measurements')\n",
    "plt.xlabel('Time (UTC)')\n",
    "xfmt = mdates.DateFormatter('%b %d %H:%M')\n",
    "ax.xaxis.set_major_formatter(xfmt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b44189c-6d4b-45b4-b60e-84802a1259e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             NaN\n",
       "1             NaN\n",
       "2             NaN\n",
       "3             NaN\n",
       "4             NaN\n",
       "           ...   \n",
       "83981    2.805189\n",
       "83982    2.805189\n",
       "83983    2.805189\n",
       "83984    2.805189\n",
       "83985    2.805189\n",
       "Name: Rolling, Length: 83986, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COD_values3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3012a89-af62-4936-aca8-c683bd004222",
   "metadata": {},
   "source": [
    "## NUEVO PLOT PARA VISUALIZAR LOS ANCHOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "185c1c4a-2fc2-45b0-8481-604fc43dbdaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'----------------------------------------------------------------------------'\n",
    "sas=np.arange(0,len(time2))\n",
    "fig, ax = plt.subplots(1)\n",
    "\n",
    "'Ploteamos el rolling average'\n",
    "plt.plot( sas , COD_values3,'-x',c='black') \n",
    " \n",
    "    \n",
    "plt.ylabel('COD Measurements')\n",
    "plt.xlabel('Time (UTC)')\n",
    "\n",
    "plt.vlines(x=sas[indicesrolling], ymin=COD_values3[indicesrolling] - properties[\"prominences\"],\n",
    "           ymax = COD_values3[indicesrolling], color = \"C1\")\n",
    "plt.hlines(y=properties[\"width_heights\"], xmin=properties[\"left_ips\"],\n",
    "           xmax=properties[\"right_ips\"], color = \"C1\")\n",
    "\n",
    "plt.plot(properties[\"left_ips\"], properties[\"width_heights\"],'X',c='red')\n",
    "plt.plot(properties[\"right_ips\"], properties[\"width_heights\"],'X',c='blue')\n",
    "\n",
    "\n",
    "# Plotea líneas verticales en cada punto\n",
    "for i in range(len(left)):\n",
    "    ax.vlines(left[i], ymin=COD_values3[left[i]], ymax=COD_values3[left[i]]+10, color='purple', linestyle='-', alpha=0.5)\n",
    "# Plotea líneas verticales en cada punto\n",
    "for i in range(len(right)):\n",
    "    ax.vlines(right[i], ymin=COD_values3[right[i]], ymax=COD_values3[right[i]]+10, color='purple', linestyle='-', alpha=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "532f0df2-8299-40bb-94a2-c34951c00cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.82301379  2.92995604  3.27154013  8.09620122  9.86320893  3.14726119\n",
      "  2.40305229  4.21815983  8.50444174  2.76490178 16.81282033  8.83918905\n",
      "  2.10639421  2.51683218 13.8418444   8.6504512  32.25295613  5.3903867\n",
      "  1.32629338]\n"
     ]
    }
   ],
   "source": [
    "print(properties[\"prominences\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47811e4c-16d8-4a3b-a847-875183ccf33e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ddbd42-c7cb-4cfd-9a45-c572e1142a31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff36fb75-dba7-41b5-83b4-f8c1751f9453",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (83986,) and (4144,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m ax1\u001b[38;5;241m=\u001b[39mplt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m211\u001b[39m,sharex\u001b[38;5;241m=\u001b[39max2)\n\u001b[0;32m     16\u001b[0m figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m20\u001b[39m,\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(time2,HT_values ,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-x\u001b[39m\u001b[38;5;124m'\u001b[39m,color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblack\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     18\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(time2,\u001b[38;5;241m10000\u001b[39m\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mlen\u001b[39m(time2)))\n\u001b[0;32m     19\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAltitude (m)\u001b[39m\u001b[38;5;124m'\u001b[39m,fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m13\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\pyplot.py:2812\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2810\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[0;32m   2811\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, scaley\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 2812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gca()\u001b[38;5;241m.\u001b[39mplot(\n\u001b[0;32m   2813\u001b[0m         \u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39mscalex, scaley\u001b[38;5;241m=\u001b[39mscaley,\n\u001b[0;32m   2814\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:1688\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1445\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1446\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1447\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1685\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1686\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1687\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[1;32m-> 1688\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[0;32m   1689\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m   1690\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\axes\\_base.py:311\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    310\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_plot_args(\n\u001b[0;32m    312\u001b[0m     this, kwargs, ambiguous_fmt_datakey\u001b[38;5;241m=\u001b[39mambiguous_fmt_datakey)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\axes\\_base.py:504\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[0;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m--> 504\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    508\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (83986,) and (4144,)"
     ]
    }
   ],
   "source": [
    "#FIRST PLOT\n",
    "plt.figure()\n",
    "ax2=plt.subplot(212)\n",
    "figsize=(20,4)\n",
    "   \n",
    "plt.plot(time, COD_values,'-x',c='black')     \n",
    "plt.plot(time, rolling,'-x',c='purple') \n",
    "#plt.text(0.01, 0.75, \"D)\", fontweight=\"bold\", fontsize=13 ,transform=ax7.transAxes)\n",
    "plt.ylabel('COD (adimensional)',fontsize=13)\n",
    "\n",
    "\n",
    "\n",
    "#SECOND PLOT\n",
    "\n",
    "ax1=plt.subplot(211,sharex=ax2)\n",
    "figsize=(20,4)\n",
    "plt.plot(time2,HT_values ,'-x',color='black')\n",
    "plt.plot(time2,10000*np.ones(len(time2)))\n",
    "plt.ylabel('Altitude (m)',fontsize=13)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
